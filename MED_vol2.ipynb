{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MED: Morphological Encoder-Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import os.path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence#, masked_cross_entropy\n",
    "from masked_cross_entropy import *\n",
    "\n",
    "from med_dataset import MEDDataset, med_collate_fn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "PAD_TOKEN = 0\n",
    "START_TOKEN = 1\n",
    "END_TOKEN = 2\n",
    "UNK_TOKEN = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, embed_size, hidden_size, n_layers=1, dropout=0.1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, embed_size, padding_idx=PAD_TOKEN)\n",
    "        self.gru = nn.GRU(embed_size, hidden_size, n_layers, dropout=self.dropout, bidirectional=True)\n",
    "        \n",
    "    def forward(self, input_seqs, input_lengths, hidden=None):\n",
    "        # Note: we run this all at once (over multiple batches of multiple sequences)\n",
    "        embedded = self.embedding(input_seqs)\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n",
    "        outputs, hidden = self.gru(packed, hidden)\n",
    "        outputs, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(outputs) # unpack (back to padded)\n",
    "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:] # Sum bidirectional outputs\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Attention Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attn(nn.Module):\n",
    "    def __init__(self, method, hidden_size):\n",
    "        super(Attn, self).__init__()\n",
    "        \n",
    "        self.method = method\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        if self.method == 'general':\n",
    "            self.attn = nn.Linear(self.hidden_size, hidden_size)\n",
    "\n",
    "        elif self.method == 'concat':\n",
    "            self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n",
    "            self.v = nn.Parameter(torch.FloatTensor(1, hidden_size))\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        max_len = encoder_outputs.size(0)\n",
    "        this_batch_size = encoder_outputs.size(1)\n",
    "\n",
    "        # Create variable to store attention energies\n",
    "        attn_energies = Variable(torch.zeros(this_batch_size, max_len)) # B x S\n",
    "\n",
    "        if USE_CUDA:\n",
    "            attn_energies = attn_energies.cuda()\n",
    "\n",
    "        # For each batch of encoder outputs\n",
    "        for b in range(this_batch_size):\n",
    "            # Calculate energy for each encoder output\n",
    "            for i in range(max_len):\n",
    "                attn_energies[b, i] = self.score(hidden[:, b], encoder_outputs[i, b].unsqueeze(0))\n",
    "\n",
    "        # Normalize energies to weights in range 0 to 1, resize to 1 x B x S\n",
    "        return F.softmax(attn_energies).unsqueeze(1)\n",
    "    \n",
    "    def score(self, hidden, encoder_output):\n",
    "        \n",
    "        if self.method == 'dot':\n",
    "            energy = hidden.dot(encoder_output)\n",
    "            return energy\n",
    "        \n",
    "        elif self.method == 'general':\n",
    "            energy = self.attn(encoder_output)\n",
    "            energy = hidden.dot(energy)\n",
    "            return energy\n",
    "        \n",
    "        elif self.method == 'concat':\n",
    "            energy = self.attn(torch.cat((hidden, encoder_output), 1))\n",
    "            energy = self.v.dot(energy)\n",
    "            return energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bahdanau et al. model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size, output_size, n_layers=1, dropout_p=0.1):\n",
    "        super(BahdanauAttnDecoderRNN, self).__init__()\n",
    "        \n",
    "        # Define parameters\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embed_size = embed_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        # Define layers\n",
    "        self.embedding = nn.Embedding(output_size, embed_size, padding_idx=PAD_TOKEN)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.attn = Attn('concat', hidden_size)\n",
    "        self.gru = nn.GRU(embed_size, hidden_size, n_layers, dropout=dropout_p)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, word_input, last_hidden, encoder_outputs):\n",
    "        # Note: we run this one step at a time\n",
    "        # TODO: FIX BATCHING\n",
    "        \n",
    "        # Get the embedding of the current input word (last output word)\n",
    "        word_embedded = self.embedding(word_input).view(1, 1, -1) # S=1 x B x N\n",
    "        word_embedded = self.dropout(word_embedded)\n",
    "        \n",
    "        # Calculate attention weights and apply to encoder outputs\n",
    "        attn_weights = self.attn(last_hidden[-1], encoder_outputs)\n",
    "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1)) # B x 1 x N\n",
    "        context = context.transpose(0, 1) # 1 x B x N\n",
    "        \n",
    "        # Combine embedded input word and attended context, run through RNN\n",
    "        rnn_input = torch.cat((word_embedded, context), 2)\n",
    "        output, hidden = self.gru(rnn_input, last_hidden)\n",
    "        \n",
    "        # Final output layer\n",
    "        output = output.squeeze(0) # B x N\n",
    "        output = F.log_softmax(self.out(torch.cat((output, context), 1)))\n",
    "        \n",
    "        # Return final output, hidden state, and attention weights (for visualization)\n",
    "        return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Luong et al. model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LuongAttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, attn_model, hidden_size, output_size, n_layers=1, dropout=0.1):\n",
    "        super(LuongAttnDecoderRNN, self).__init__()\n",
    "\n",
    "        # Keep for reference\n",
    "        self.attn_model = attn_model\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Define layers\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size, padding_idx=PAD_TOKEN)\n",
    "        self.embedding_dropout = nn.Dropout(dropout)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=dropout)\n",
    "        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        # Choose attention model\n",
    "        if attn_model != 'none':\n",
    "            self.attn = Attn(attn_model, hidden_size)\n",
    "\n",
    "    def forward(self, input_seq, last_hidden, encoder_outputs):\n",
    "        # Note: we run this one step at a time\n",
    "\n",
    "        # Get the embedding of the current input word (last output word)\n",
    "        batch_size = input_seq.size(0)\n",
    "        embedded = self.embedding(input_seq)\n",
    "        embedded = self.embedding_dropout(embedded)\n",
    "        embedded = embedded.view(1, batch_size, self.hidden_size) # S=1 x B x N\n",
    "\n",
    "        # Get current hidden state from input word and last hidden state\n",
    "        rnn_output, hidden = self.gru(embedded, last_hidden)\n",
    "\n",
    "        # Calculate attention from current RNN state and all encoder outputs;\n",
    "        # apply to encoder outputs to get weighted average\n",
    "        attn_weights = self.attn(rnn_output, encoder_outputs)\n",
    "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1)) # B x S=1 x N\n",
    "\n",
    "        # Attentional vector using the RNN hidden state and context vector\n",
    "        # concatenated together (Luong eq. 5)\n",
    "        rnn_output = rnn_output.squeeze(0) # S=1 x B x N -> B x N\n",
    "        context = context.squeeze(1)       # B x S=1 x N -> B x N\n",
    "        concat_input = torch.cat((rnn_output, context), 1)\n",
    "        concat_output = F.tanh(self.concat(concat_input))\n",
    "\n",
    "        # Finally predict next token (Luong eq. 6, without softmax)\n",
    "        output = self.out(concat_output)\n",
    "\n",
    "        # Return final output, hidden state, and attention weights (for visualization)\n",
    "        return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(src_batch, src_lens, trg_batch, trg_lens, encoder, decoder, \n",
    "               encoder_optimizer, decoder_optimizer, criterion):\n",
    "    \n",
    "    # Zero gradients of both optimizers\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    #loss = 0 # Added onto for each word\n",
    "\n",
    "    # Run words through encoder\n",
    "    encoder_outputs, encoder_hidden = encoder(src_batch, src_lens, None)\n",
    "    \n",
    "    # Prepare input and output variables\n",
    "    decoder_input = Variable(torch.LongTensor([START_TOKEN] * batch_size))\n",
    "    decoder_hidden = encoder_hidden[:decoder.n_layers] # Use last (forward) hidden state from encoder\n",
    "\n",
    "    max_trg_len = max(trg_lens)\n",
    "    all_decoder_outputs = Variable(torch.zeros(max_trg_len, batch_size, decoder.output_size))\n",
    "\n",
    "    # Move new Variables to CUDA\n",
    "    if USE_CUDA:\n",
    "        decoder_input = decoder_input.cuda()\n",
    "        all_decoder_outputs = all_decoder_outputs.cuda()\n",
    "\n",
    "    # Run through decoder one time step at a time\n",
    "    for t in range(max_trg_len):\n",
    "        decoder_output, decoder_hidden, decoder_attn = decoder(\n",
    "            decoder_input, decoder_hidden, encoder_outputs\n",
    "        )\n",
    "\n",
    "        all_decoder_outputs[t] = decoder_output\n",
    "        decoder_input = trg_batch[t] # Next input is current target\n",
    "\n",
    "    # Loss calculation and backpropagation\n",
    "    loss = masked_cross_entropy(\n",
    "        all_decoder_outputs.transpose(0, 1).contiguous(), # -> batch x seq\n",
    "        trg_batch.transpose(0, 1).contiguous(), # -> batch x seq\n",
    "        trg_lens\n",
    "    )\n",
    "    loss.backward()\n",
    "    \n",
    "    # Clip gradient norms\n",
    "    enc_grads = torch.nn.utils.clip_grad_norm(encoder.parameters(), clip)\n",
    "    dec_grads = torch.nn.utils.clip_grad_norm(decoder.parameters(), clip)\n",
    "\n",
    "    # Update parameters with optimizers\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return loss.data[0]#, enc_grads, dec_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(encoder, decoder, checkpoint_dir):\n",
    "    enc_filename = \"{}/enc-{}.pth\".format(checkpoint_dir, time.strftime(\"%d%m%y-%H%M%S\"))\n",
    "    dec_filename = \"{}/dec-{}.pth\".format(checkpoint_dir, time.strftime(\"%d%m%y-%H%M%S\"))\n",
    "    #if not os.path.isfile(enc_filename):\n",
    "    #    open(enc_filename, 'w+')\n",
    "    #if not os.path.isfile(dec_filename):\n",
    "    #    open(dec_filename, 'w+')\n",
    "    torch.save(encoder.state_dict(), enc_filename)\n",
    "    torch.save(decoder.state_dict(), dec_filename)\n",
    "    print(\"Model saved.\")\n",
    "\n",
    "def train(dataset, batch_size, n_epochs, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, \n",
    "          checkpoint_dir=None, save_every=500):\n",
    "    train_iter = DataLoader(dataset=dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=True,\n",
    "                            num_workers=4,\n",
    "                            collate_fn=med_collate_fn)\n",
    "    for i in range(n_epochs):\n",
    "        tick = time.clock()\n",
    "        print(\"Epoch {}/{}\".format(i+1, n_epochs))\n",
    "        losses = []\n",
    "        for batch_idx, batch in enumerate(train_iter):\n",
    "            input_batch, input_lengths, target_batch, target_lengths = batch\n",
    "            loss = train_step(input_batch, input_lengths, target_batch, target_lengths, \n",
    "                                 encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "            losses.append(loss)\n",
    "            if batch_idx % 100 == 0:\n",
    "                print(\"batch: {}, loss: {}\".format(batch_idx, loss))\n",
    "            if checkpoint_dir:\n",
    "                if batch_idx % save_every == 0:\n",
    "                    save_checkpoint(encoder, decoder, checkpoint_dir)\n",
    "        tock = time.clock()\n",
    "        print(\"Time: {} Avg loss: {}\".format(tock-tick, np.mean(losses)))\n",
    "    \n",
    "    if checkpoint_dir:\n",
    "        save_checkpoint(encoder, decoder, checkpoint_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring and Initializing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure models\n",
    "attn_model = 'dot'\n",
    "hidden_size = 100\n",
    "embed_size = 300\n",
    "n_layers = 1\n",
    "dropout = 0.1\n",
    "batch_size = 20\n",
    "checkpoint_dir = \"checkpoints\"\n",
    "\n",
    "# Configure training/optimization\n",
    "clip = 50.0\n",
    "teacher_forcing_ratio = 0.5\n",
    "learning_rate = 0.0001\n",
    "decoder_learning_ratio = 5.0\n",
    "n_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dataset\n",
    "dataset = MEDDataset(\"data/german-task2-trainval\")\n",
    "\n",
    "# Initialize models\n",
    "encoder = EncoderRNN(len(dataset.in_vocab[0]), embed_size, hidden_size, n_layers, dropout=dropout)\n",
    "decoder = LuongAttnDecoderRNN(attn_model, hidden_size, len(dataset.out_vocab[0]), n_layers, dropout=dropout)\n",
    "\n",
    "# Initialize optimizers and criterion\n",
    "#encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "#decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n",
    "encoder_optimizer = optim.Adadelta(encoder.parameters())\n",
    "decoder_optimizer = optim.Adadelta(decoder.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Move models to GPU\n",
    "if USE_CUDA:\n",
    "    encoder.cuda()\n",
    "    decoder.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tome/anaconda3/envs/pytorch/lib/python3.6/site-packages/ipykernel/__main__.py:32: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/home/tome/faks/reinflection_projekt/Morphological-Encoder-Decoder/masked_cross_entropy.py:45: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_probs_flat = functional.log_softmax(logits_flat)\n",
      "/home/tome/faks/reinflection_projekt/Morphological-Encoder-Decoder/masked_cross_entropy.py:11: UserWarning: torch.range is deprecated in favor of torch.arange and will be removed in 0.3. Note that arange generates values in [start; end), not [start; end].\n",
      "  seq_range = torch.range(0, max_len - 1).long()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0, loss: 3.5402915477752686\n",
      "Model saved.\n",
      "batch: 100, loss: 0.8323646783828735\n",
      "batch: 200, loss: 0.4349044859409332\n",
      "batch: 300, loss: 0.3329000174999237\n",
      "batch: 400, loss: 0.38507094979286194\n",
      "batch: 500, loss: 0.26567062735557556\n",
      "Model saved.\n",
      "batch: 600, loss: 0.35699963569641113\n",
      "batch: 700, loss: 0.2322836071252823\n",
      "batch: 800, loss: 0.210947185754776\n",
      "batch: 900, loss: 0.2357427328824997\n",
      "batch: 1000, loss: 0.32792016863822937\n",
      "Model saved.\n",
      "batch: 1100, loss: 0.25465595722198486\n",
      "batch: 1200, loss: 0.3827567398548126\n",
      "batch: 1300, loss: 0.20417553186416626\n",
      "batch: 1400, loss: 0.24652105569839478\n",
      "Time: 4499.272427 Avg loss: 0.41491505569881865\n",
      "Epoch 2/20\n",
      "batch: 0, loss: 0.23960116505622864\n",
      "Model saved.\n",
      "batch: 100, loss: 0.22763650119304657\n",
      "batch: 200, loss: 0.2599289119243622\n",
      "batch: 300, loss: 0.2652410864830017\n",
      "batch: 400, loss: 0.2060348242521286\n",
      "batch: 500, loss: 0.13266746699810028\n",
      "Model saved.\n",
      "batch: 600, loss: 0.17238198220729828\n",
      "batch: 700, loss: 0.30676597356796265\n",
      "batch: 800, loss: 0.2021716684103012\n",
      "batch: 900, loss: 0.1864839345216751\n",
      "batch: 1000, loss: 0.19094184041023254\n",
      "Model saved.\n",
      "batch: 1100, loss: 0.19123490154743195\n",
      "batch: 1200, loss: 0.2430565506219864\n",
      "batch: 1300, loss: 0.18513886630535126\n",
      "batch: 1400, loss: 0.22843053936958313\n",
      "Time: 4582.903011000001 Avg loss: 0.20078686280176045\n",
      "Epoch 3/20\n",
      "batch: 0, loss: 0.18347442150115967\n",
      "Model saved.\n",
      "batch: 100, loss: 0.1742343008518219\n",
      "batch: 200, loss: 0.18443050980567932\n",
      "batch: 300, loss: 0.17744608223438263\n",
      "batch: 400, loss: 0.1766812950372696\n",
      "batch: 500, loss: 0.20222824811935425\n",
      "Model saved.\n",
      "batch: 600, loss: 0.18193590641021729\n",
      "batch: 700, loss: 0.17106717824935913\n",
      "batch: 800, loss: 0.21318411827087402\n",
      "batch: 900, loss: 0.11705439537763596\n",
      "batch: 1000, loss: 0.1323084980249405\n",
      "Model saved.\n",
      "batch: 1100, loss: 0.16241787374019623\n",
      "batch: 1200, loss: 0.20427371561527252\n",
      "batch: 1300, loss: 0.08909720182418823\n",
      "batch: 1400, loss: 0.15702654421329498\n",
      "Time: 4729.055632 Avg loss: 0.16242350291771193\n",
      "Epoch 4/20\n",
      "batch: 0, loss: 0.15399020910263062\n",
      "Model saved.\n",
      "batch: 100, loss: 0.16542719304561615\n",
      "batch: 200, loss: 0.14735034108161926\n",
      "batch: 300, loss: 0.14333900809288025\n",
      "batch: 400, loss: 0.17929917573928833\n",
      "batch: 500, loss: 0.1755182445049286\n",
      "Model saved.\n",
      "batch: 600, loss: 0.08055394142866135\n",
      "batch: 700, loss: 0.18286940455436707\n",
      "batch: 800, loss: 0.1659812331199646\n",
      "batch: 900, loss: 0.11445696651935577\n",
      "batch: 1000, loss: 0.1536037027835846\n",
      "Model saved.\n",
      "batch: 1100, loss: 0.10384723544120789\n",
      "batch: 1200, loss: 0.1320144087076187\n",
      "batch: 1300, loss: 0.181550532579422\n",
      "batch: 1400, loss: 0.12513653934001923\n",
      "Time: 4514.88896 Avg loss: 0.1407359439853786\n",
      "Epoch 5/20\n",
      "batch: 0, loss: 0.10282456874847412\n",
      "Model saved.\n",
      "batch: 100, loss: 0.09512375295162201\n",
      "batch: 200, loss: 0.19298647344112396\n",
      "batch: 300, loss: 0.1152644231915474\n",
      "batch: 400, loss: 0.10161779075860977\n",
      "batch: 500, loss: 0.10747434198856354\n",
      "Model saved.\n",
      "batch: 600, loss: 0.17769692838191986\n",
      "batch: 700, loss: 0.09673552960157394\n",
      "batch: 800, loss: 0.15430858731269836\n",
      "batch: 900, loss: 0.08204776048660278\n",
      "batch: 1000, loss: 0.1310950368642807\n",
      "Model saved.\n",
      "batch: 1100, loss: 0.10157010704278946\n",
      "batch: 1200, loss: 0.11834268271923065\n",
      "batch: 1300, loss: 0.13699978590011597\n",
      "batch: 1400, loss: 0.1595962941646576\n",
      "Time: 4605.091511999999 Avg loss: 0.12543626262340696\n",
      "Epoch 6/20\n",
      "batch: 0, loss: 0.1863425076007843\n",
      "Model saved.\n",
      "batch: 100, loss: 0.09912284463644028\n",
      "batch: 200, loss: 0.11071711033582687\n",
      "batch: 300, loss: 0.1498483121395111\n",
      "batch: 400, loss: 0.13931280374526978\n",
      "batch: 500, loss: 0.06720641255378723\n",
      "Model saved.\n",
      "batch: 600, loss: 0.12427148222923279\n",
      "batch: 700, loss: 0.0933387279510498\n",
      "batch: 800, loss: 0.11962027847766876\n",
      "batch: 900, loss: 0.04827193543314934\n",
      "batch: 1000, loss: 0.11555276811122894\n",
      "Model saved.\n",
      "batch: 1100, loss: 0.17620395123958588\n",
      "batch: 1200, loss: 0.21074077486991882\n",
      "batch: 1300, loss: 0.11093895882368088\n",
      "batch: 1400, loss: 0.08382979780435562\n",
      "Time: 4578.27118 Avg loss: 0.11209568249889545\n",
      "Epoch 7/20\n",
      "batch: 0, loss: 0.06483929604291916\n",
      "Model saved.\n",
      "batch: 100, loss: 0.11604529619216919\n",
      "batch: 200, loss: 0.06089555844664574\n",
      "batch: 300, loss: 0.09283420443534851\n",
      "batch: 400, loss: 0.10154778510332108\n",
      "batch: 500, loss: 0.10791350156068802\n",
      "Model saved.\n",
      "batch: 600, loss: 0.09236204624176025\n",
      "batch: 700, loss: 0.10788822919130325\n",
      "batch: 800, loss: 0.08213790506124496\n",
      "batch: 900, loss: 0.08018957078456879\n",
      "batch: 1000, loss: 0.11108536273241043\n",
      "Model saved.\n",
      "batch: 1100, loss: 0.11396414041519165\n",
      "batch: 1200, loss: 0.0942077487707138\n",
      "batch: 1300, loss: 0.07015936076641083\n",
      "batch: 1400, loss: 0.0856151133775711\n",
      "Time: 4584.534379000001 Avg loss: 0.10364707668518855\n",
      "Epoch 8/20\n",
      "batch: 0, loss: 0.09719055891036987\n",
      "Model saved.\n",
      "batch: 100, loss: 0.0984688475728035\n",
      "batch: 200, loss: 0.06803056597709656\n",
      "batch: 300, loss: 0.09503831714391708\n",
      "batch: 400, loss: 0.10260122269392014\n",
      "batch: 500, loss: 0.08619298785924911\n",
      "Model saved.\n",
      "batch: 600, loss: 0.13908950984477997\n",
      "batch: 700, loss: 0.08870237320661545\n",
      "batch: 800, loss: 0.0730861946940422\n",
      "batch: 900, loss: 0.07014475017786026\n",
      "batch: 1000, loss: 0.07834187150001526\n",
      "Model saved.\n",
      "batch: 1100, loss: 0.05739941820502281\n",
      "batch: 1200, loss: 0.07164354622364044\n",
      "batch: 1300, loss: 0.15312057733535767\n",
      "batch: 1400, loss: 0.055900897830724716\n",
      "Time: 4754.817084999999 Avg loss: 0.09774054754525423\n",
      "Epoch 9/20\n",
      "batch: 0, loss: 0.07834359258413315\n",
      "Model saved.\n",
      "batch: 100, loss: 0.0891418606042862\n",
      "batch: 200, loss: 0.07872705906629562\n",
      "batch: 300, loss: 0.05273285135626793\n",
      "batch: 400, loss: 0.07447084784507751\n",
      "batch: 500, loss: 0.09940910339355469\n",
      "Model saved.\n",
      "batch: 600, loss: 0.10936840623617172\n",
      "batch: 700, loss: 0.0808720737695694\n",
      "batch: 800, loss: 0.12523649632930756\n",
      "batch: 900, loss: 0.11892863363027573\n",
      "batch: 1000, loss: 0.0553613007068634\n",
      "Model saved.\n",
      "batch: 1100, loss: 0.08429912477731705\n",
      "batch: 1200, loss: 0.0744415670633316\n",
      "batch: 1300, loss: 0.07623618096113205\n",
      "batch: 1400, loss: 0.08944004774093628\n",
      "Time: 4351.716963999999 Avg loss: 0.0931906376266852\n",
      "Epoch 10/20\n",
      "batch: 0, loss: 0.1132727712392807\n",
      "Model saved.\n",
      "batch: 100, loss: 0.07146152853965759\n",
      "batch: 200, loss: 0.06621471047401428\n",
      "batch: 300, loss: 0.10670045763254166\n",
      "batch: 400, loss: 0.10456810146570206\n",
      "batch: 500, loss: 0.084881491959095\n",
      "Model saved.\n",
      "batch: 600, loss: 0.09836113452911377\n",
      "batch: 700, loss: 0.08817191421985626\n",
      "batch: 800, loss: 0.061168037354946136\n",
      "batch: 900, loss: 0.07706059515476227\n",
      "batch: 1000, loss: 0.09093236178159714\n",
      "Model saved.\n",
      "batch: 1100, loss: 0.048444535583257675\n",
      "batch: 1200, loss: 0.058222897350788116\n",
      "batch: 1300, loss: 0.0899578183889389\n",
      "batch: 1400, loss: 0.06691987067461014\n",
      "Time: 5044.528214999998 Avg loss: 0.0873256971852647\n",
      "Epoch 11/20\n",
      "batch: 0, loss: 0.08087043464183807\n",
      "Model saved.\n",
      "batch: 100, loss: 0.05723472684621811\n",
      "batch: 200, loss: 0.08872300386428833\n",
      "batch: 300, loss: 0.06182130053639412\n",
      "batch: 400, loss: 0.06570640206336975\n",
      "batch: 500, loss: 0.1012943834066391\n",
      "Model saved.\n",
      "batch: 600, loss: 0.097695492208004\n",
      "batch: 700, loss: 0.08734024316072464\n",
      "batch: 800, loss: 0.08067651093006134\n",
      "batch: 900, loss: 0.1063157394528389\n",
      "batch: 1000, loss: 0.08864293247461319\n",
      "Model saved.\n",
      "batch: 1100, loss: 0.03993996977806091\n",
      "batch: 1200, loss: 0.05871915817260742\n",
      "batch: 1300, loss: 0.11174917221069336\n",
      "batch: 1400, loss: 0.08153759688138962\n",
      "Time: 4414.511833999997 Avg loss: 0.08242800729090555\n",
      "Epoch 12/20\n",
      "batch: 0, loss: 0.06419121474027634\n",
      "Model saved.\n",
      "batch: 100, loss: 0.11373644322156906\n",
      "batch: 200, loss: 0.04777362942695618\n",
      "batch: 300, loss: 0.07114900648593903\n",
      "batch: 400, loss: 0.11754906922578812\n",
      "batch: 500, loss: 0.04946443438529968\n",
      "Model saved.\n",
      "batch: 600, loss: 0.04982587695121765\n",
      "batch: 700, loss: 0.05268014222383499\n",
      "batch: 800, loss: 0.057217422872781754\n",
      "batch: 900, loss: 0.081832155585289\n",
      "batch: 1000, loss: 0.12475204467773438\n",
      "Model saved.\n",
      "batch: 1100, loss: 0.07557403296232224\n",
      "batch: 1200, loss: 0.07004072517156601\n",
      "batch: 1300, loss: 0.15218788385391235\n",
      "batch: 1400, loss: 0.0592544861137867\n",
      "Time: 4589.554539999997 Avg loss: 0.0808614843693148\n",
      "Epoch 13/20\n",
      "batch: 0, loss: 0.05566313490271568\n",
      "Model saved.\n",
      "batch: 100, loss: 0.11696288734674454\n",
      "batch: 200, loss: 0.053364068269729614\n",
      "batch: 300, loss: 0.054729510098695755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 400, loss: 0.06565453112125397\n",
      "batch: 500, loss: 0.11904729902744293\n",
      "Model saved.\n",
      "batch: 600, loss: 0.10509301722049713\n",
      "batch: 700, loss: 0.07354678958654404\n",
      "batch: 800, loss: 0.04992707818746567\n",
      "batch: 900, loss: 0.08854195475578308\n",
      "batch: 1000, loss: 0.0606839656829834\n",
      "Model saved.\n",
      "batch: 1100, loss: 0.089202880859375\n",
      "batch: 1200, loss: 0.07310362905263901\n",
      "batch: 1300, loss: 0.0950426384806633\n",
      "batch: 1400, loss: 0.06496687978506088\n",
      "Time: 4700.249039000002 Avg loss: 0.07715402023556332\n",
      "Epoch 14/20\n",
      "batch: 0, loss: 0.07330381870269775\n",
      "Model saved.\n",
      "batch: 100, loss: 0.047183092683553696\n",
      "batch: 200, loss: 0.06077221408486366\n",
      "batch: 300, loss: 0.07203900068998337\n",
      "batch: 400, loss: 0.09074711054563522\n",
      "batch: 500, loss: 0.08437108993530273\n",
      "Model saved.\n",
      "batch: 600, loss: 0.08790136128664017\n",
      "batch: 700, loss: 0.09158164262771606\n",
      "batch: 800, loss: 0.06460535526275635\n",
      "batch: 900, loss: 0.050453972071409225\n",
      "batch: 1000, loss: 0.0682794600725174\n",
      "Model saved.\n",
      "batch: 1100, loss: 0.10449367761611938\n",
      "batch: 1200, loss: 0.06756091117858887\n",
      "batch: 1300, loss: 0.10700596123933792\n",
      "batch: 1400, loss: 0.05449620261788368\n",
      "Time: 5004.716662999999 Avg loss: 0.07376756273442879\n",
      "Epoch 15/20\n",
      "batch: 0, loss: 0.09727908670902252\n",
      "Model saved.\n",
      "batch: 100, loss: 0.04084387794137001\n",
      "batch: 200, loss: 0.062442537397146225\n",
      "batch: 300, loss: 0.06964927166700363\n",
      "batch: 400, loss: 0.055759746581315994\n",
      "batch: 500, loss: 0.07115865498781204\n",
      "Model saved.\n",
      "batch: 600, loss: 0.055001888424158096\n",
      "batch: 700, loss: 0.036228328943252563\n",
      "batch: 800, loss: 0.07872649282217026\n",
      "batch: 900, loss: 0.07350712269544601\n",
      "batch: 1000, loss: 0.04279245063662529\n",
      "Model saved.\n",
      "batch: 1100, loss: 0.0763302817940712\n",
      "batch: 1200, loss: 0.08023898303508759\n",
      "batch: 1300, loss: 0.07607978582382202\n",
      "batch: 1400, loss: 0.05722174048423767\n",
      "Time: 4457.795726999997 Avg loss: 0.07169036723983785\n",
      "Epoch 16/20\n",
      "batch: 0, loss: 0.05306480824947357\n",
      "Model saved.\n",
      "batch: 100, loss: 0.10406989604234695\n",
      "batch: 200, loss: 0.05093161761760712\n",
      "batch: 300, loss: 0.0683162584900856\n",
      "batch: 400, loss: 0.08932090550661087\n",
      "batch: 500, loss: 0.06514506042003632\n",
      "Model saved.\n",
      "batch: 600, loss: 0.06344617903232574\n",
      "batch: 700, loss: 0.06044622138142586\n",
      "batch: 800, loss: 0.12784814834594727\n",
      "batch: 900, loss: 0.05792289227247238\n",
      "batch: 1000, loss: 0.04497123137116432\n",
      "Model saved.\n",
      "batch: 1100, loss: 0.08283010125160217\n",
      "batch: 1200, loss: 0.07329336553812027\n",
      "batch: 1300, loss: 0.1041712760925293\n",
      "batch: 1400, loss: 0.07921130210161209\n",
      "Time: 4560.242311000009 Avg loss: 0.07133299805896563\n",
      "Epoch 17/20\n",
      "batch: 0, loss: 0.07526329159736633\n",
      "Model saved.\n",
      "batch: 100, loss: 0.08228395879268646\n",
      "batch: 200, loss: 0.07544611394405365\n",
      "batch: 300, loss: 0.056094978004693985\n",
      "batch: 400, loss: 0.11024384200572968\n",
      "batch: 500, loss: 0.04694761335849762\n",
      "Model saved.\n",
      "batch: 600, loss: 0.0857740268111229\n",
      "batch: 700, loss: 0.05975071340799332\n",
      "batch: 800, loss: 0.06382525712251663\n",
      "batch: 900, loss: 0.03583036735653877\n",
      "batch: 1000, loss: 0.11268038302659988\n",
      "Model saved.\n",
      "batch: 1100, loss: 0.06260988861322403\n",
      "batch: 1200, loss: 0.06236140802502632\n",
      "batch: 1300, loss: 0.061213765293359756\n",
      "batch: 1400, loss: 0.06315593421459198\n",
      "Time: 4526.556202000007 Avg loss: 0.06942790909023541\n",
      "Epoch 18/20\n",
      "batch: 0, loss: 0.05575322359800339\n",
      "Model saved.\n",
      "batch: 100, loss: 0.08503586053848267\n",
      "batch: 200, loss: 0.0716637447476387\n",
      "batch: 300, loss: 0.04061663895845413\n",
      "batch: 400, loss: 0.05685427412390709\n",
      "batch: 500, loss: 0.06832308322191238\n",
      "Model saved.\n",
      "batch: 600, loss: 0.1331750899553299\n",
      "batch: 700, loss: 0.06543561071157455\n",
      "batch: 800, loss: 0.09967511892318726\n",
      "batch: 900, loss: 0.11696790158748627\n",
      "batch: 1000, loss: 0.052120815962553024\n",
      "Model saved.\n",
      "batch: 1100, loss: 0.05534055829048157\n",
      "batch: 1200, loss: 0.07301337271928787\n",
      "batch: 1300, loss: 0.10695888847112656\n",
      "batch: 1400, loss: 0.0754774808883667\n",
      "Time: 4434.080344000002 Avg loss: 0.06690929901993109\n",
      "Epoch 19/20\n",
      "batch: 0, loss: 0.053939204663038254\n",
      "Model saved.\n",
      "batch: 100, loss: 0.11268849670886993\n",
      "batch: 200, loss: 0.047084636986255646\n",
      "batch: 300, loss: 0.07222709059715271\n",
      "batch: 400, loss: 0.07545044273138046\n",
      "batch: 500, loss: 0.05670260637998581\n",
      "Model saved.\n",
      "batch: 600, loss: 0.06126135587692261\n",
      "batch: 700, loss: 0.050178252160549164\n",
      "batch: 800, loss: 0.0773453339934349\n",
      "batch: 900, loss: 0.10140681266784668\n",
      "batch: 1000, loss: 0.06411844491958618\n",
      "Model saved.\n",
      "batch: 1100, loss: 0.04986239969730377\n",
      "batch: 1200, loss: 0.11356687545776367\n",
      "batch: 1300, loss: 0.06755480170249939\n",
      "batch: 1400, loss: 0.044914957135915756\n",
      "Time: 4403.690440000006 Avg loss: 0.06553664871413882\n",
      "Epoch 20/20\n",
      "batch: 0, loss: 0.08292043209075928\n",
      "Model saved.\n",
      "batch: 100, loss: 0.06104602292180061\n",
      "batch: 200, loss: 0.04647819697856903\n",
      "batch: 300, loss: 0.06926659494638443\n",
      "batch: 400, loss: 0.047149356454610825\n",
      "batch: 500, loss: 0.07161961495876312\n",
      "Model saved.\n",
      "batch: 600, loss: 0.05058642476797104\n",
      "batch: 700, loss: 0.04072878509759903\n",
      "batch: 800, loss: 0.0604209303855896\n",
      "batch: 900, loss: 0.06263750791549683\n",
      "batch: 1000, loss: 0.054765958338975906\n",
      "Model saved.\n",
      "batch: 1100, loss: 0.05032144486904144\n",
      "batch: 1200, loss: 0.0606660395860672\n",
      "batch: 1300, loss: 0.06474073976278305\n",
      "batch: 1400, loss: 0.09001397341489792\n",
      "Time: 4569.796098999999 Avg loss: 0.06529184378321386\n",
      "Model saved.\n"
     ]
    }
   ],
   "source": [
    "#encoder.load_state_dict(torch.load(\"checkpoints/enc-160518-101204.pth\"))\n",
    "#decoder.load_state_dict(torch.load(\"checkpoints/dec-160518-101204.pth\"))\n",
    "\n",
    "train(dataset, \n",
    "      batch_size, \n",
    "      n_epochs, \n",
    "      encoder, \n",
    "      decoder, \n",
    "      encoder_optimizer, \n",
    "      decoder_optimizer, \n",
    "      criterion, \n",
    "      checkpoint_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(input_seq, input_len, encoder, decoder, max_length=40):\n",
    "    #input_lengths = [len(input_seq)]\n",
    "    #input_seqs = [indexes_from_sentence(input_lang, input_seq)]\n",
    "    #input_batches = Variable(torch.LongTensor(input_seqs), volatile=True).transpose(0, 1)\n",
    "    input_seq = Variable(input_seq, volatile=True)\n",
    "    \n",
    "    if USE_CUDA:\n",
    "        input_seq = input_seq.cuda()\n",
    "        \n",
    "    # Set to not-training mode to disable dropout\n",
    "    encoder.train(False)\n",
    "    decoder.train(False)\n",
    "    \n",
    "    # Run through encoder\n",
    "    encoder_outputs, encoder_hidden = encoder(input_seq, input_len, None)\n",
    "\n",
    "    # Create starting vectors for decoder\n",
    "    decoder_input = Variable(torch.LongTensor([START_TOKEN]), volatile=True) # SOS\n",
    "    decoder_hidden = encoder_hidden[:decoder.n_layers] # Use last (forward) hidden state from encoder\n",
    "    \n",
    "    if USE_CUDA:\n",
    "        decoder_input = decoder_input.cuda()\n",
    "\n",
    "    # Store output words and attention states\n",
    "    decoded_chars = []\n",
    "    decoder_attentions = torch.zeros(max_length + 1, max_length + 1)\n",
    "    \n",
    "    # Run through decoder\n",
    "    for t in range(max_length):\n",
    "        decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "            decoder_input, decoder_hidden, encoder_outputs\n",
    "        )\n",
    "        #decoder_attentions[t,:decoder_attention.size(2)] += decoder_attention.squeeze(0).squeeze(0).cpu().data\n",
    "\n",
    "        # Choose top word from output\n",
    "        prob, token_idx = decoder_output.data.topk(1)\n",
    "        tok = token_idx[0][0]\n",
    "        if tok == END_TOKEN:\n",
    "            break\n",
    "        else:\n",
    "            decoded_chars.append(dataset.out_vocab[0][tok])\n",
    "            \n",
    "        # Next input is chosen word\n",
    "        decoder_input = Variable(torch.LongTensor([tok]))\n",
    "        if USE_CUDA: decoder_input = decoder_input.cuda()\n",
    "\n",
    "    # Set back to training mode\n",
    "    encoder.train(True)\n",
    "    decoder.train(True)\n",
    "    \n",
    "    return \"\".join(decoded_chars), decoder_attentions[:t+1, :len(encoder_outputs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_dataset(file_name, encoder, decoder):\n",
    "    dataset = MEDDataset(file_name, train=False)\n",
    "    test_iter = DataLoader(dataset=dataset,\n",
    "                           batch_size=1,\n",
    "                            shuffle=False,\n",
    "                            num_workers=4,\n",
    "                            collate_fn=med_collate_fn)\n",
    "    \n",
    "    decoded_words = []\n",
    "    for input_seq, input_len, _, _ in test_iter:\n",
    "        decoded_word, attentions = translate(input_seq, input_len, encoder, decoder)\n",
    "        decoded_words.append(decoded_word)\n",
    "        \n",
    "    with open(file_name + \"-results2\", 'w') as outfile:\n",
    "        outfile.write(\"\\n\".join(decoded_words))\n",
    "    print(\"Finished translating!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tome/anaconda3/envs/pytorch/lib/python3.6/site-packages/ipykernel/__main__.py:32: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished translating!\n"
     ]
    }
   ],
   "source": [
    "encoder.load_state_dict(torch.load(\"checkpoints/enc-180518-085634.pth\"))\n",
    "decoder.load_state_dict(torch.load(\"checkpoints/dec-180518-085634.pth\"))\n",
    "translate_dataset(\"data/german-task2-test\", encoder, decoder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
