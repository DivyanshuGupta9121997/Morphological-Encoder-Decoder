{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MED: Morphological Encoder-Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import os.path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence#, masked_cross_entropy\n",
    "from masked_cross_entropy import *\n",
    "\n",
    "from med_dataset import MEDDataset, med_collate_fn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "PAD_TOKEN = 0\n",
    "START_TOKEN = 1\n",
    "END_TOKEN = 2\n",
    "UNK_TOKEN = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, embed_size, hidden_size, n_layers=1, dropout=0.1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, embed_size, padding_idx=PAD_TOKEN)\n",
    "        self.gru = nn.GRU(embed_size, hidden_size, n_layers, dropout=self.dropout, bidirectional=True)\n",
    "        \n",
    "    def forward(self, input_seqs, input_lengths, hidden=None):\n",
    "        # Note: we run this all at once (over multiple batches of multiple sequences)\n",
    "        embedded = self.embedding(input_seqs)\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n",
    "        outputs, hidden = self.gru(packed, hidden)\n",
    "        outputs, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(outputs) # unpack (back to padded)\n",
    "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:] # Sum bidirectional outputs\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Attention Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attn(nn.Module):\n",
    "    def __init__(self, method, hidden_size):\n",
    "        super(Attn, self).__init__()\n",
    "        \n",
    "        self.method = method\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        if self.method == 'general':\n",
    "            self.attn = nn.Linear(self.hidden_size, hidden_size)\n",
    "\n",
    "        elif self.method == 'concat':\n",
    "            self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n",
    "            self.v = nn.Parameter(torch.FloatTensor(1, hidden_size))\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        max_len = encoder_outputs.size(0)\n",
    "        this_batch_size = encoder_outputs.size(1)\n",
    "\n",
    "        # Create variable to store attention energies\n",
    "        attn_energies = Variable(torch.zeros(this_batch_size, max_len)) # B x S\n",
    "\n",
    "        if USE_CUDA:\n",
    "            attn_energies = attn_energies.cuda()\n",
    "\n",
    "        # For each batch of encoder outputs\n",
    "        for b in range(this_batch_size):\n",
    "            # Calculate energy for each encoder output\n",
    "            for i in range(max_len):\n",
    "                attn_energies[b, i] = self.score(hidden[:, b], encoder_outputs[i, b].unsqueeze(0))\n",
    "\n",
    "        # Normalize energies to weights in range 0 to 1, resize to 1 x B x S\n",
    "        return F.softmax(attn_energies).unsqueeze(1)\n",
    "    \n",
    "    def score(self, hidden, encoder_output):\n",
    "        \n",
    "        if self.method == 'dot':\n",
    "            energy = hidden.dot(encoder_output)\n",
    "            return energy\n",
    "        \n",
    "        elif self.method == 'general':\n",
    "            energy = self.attn(encoder_output)\n",
    "            energy = hidden.dot(energy)\n",
    "            return energy\n",
    "        \n",
    "        elif self.method == 'concat':\n",
    "            energy = self.attn(torch.cat((hidden, encoder_output), 1))\n",
    "            energy = self.v.dot(energy)\n",
    "            return energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bahdanau et al. model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size, output_size, n_layers=1, dropout_p=0.1):\n",
    "        super(BahdanauAttnDecoderRNN, self).__init__()\n",
    "        \n",
    "        # Define parameters\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embed_size = embed_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        # Define layers\n",
    "        self.embedding = nn.Embedding(output_size, embed_size, padding_idx=PAD_TOKEN)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.attn = Attn('concat', hidden_size)\n",
    "        self.gru = nn.GRU(embed_size, hidden_size, n_layers, dropout=dropout_p)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, word_input, last_hidden, encoder_outputs):\n",
    "        # Note: we run this one step at a time\n",
    "        # TODO: FIX BATCHING\n",
    "        \n",
    "        # Get the embedding of the current input word (last output word)\n",
    "        word_embedded = self.embedding(word_input).view(1, 1, -1) # S=1 x B x N\n",
    "        word_embedded = self.dropout(word_embedded)\n",
    "        \n",
    "        # Calculate attention weights and apply to encoder outputs\n",
    "        attn_weights = self.attn(last_hidden[-1], encoder_outputs)\n",
    "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1)) # B x 1 x N\n",
    "        context = context.transpose(0, 1) # 1 x B x N\n",
    "        \n",
    "        # Combine embedded input word and attended context, run through RNN\n",
    "        rnn_input = torch.cat((word_embedded, context), 2)\n",
    "        output, hidden = self.gru(rnn_input, last_hidden)\n",
    "        \n",
    "        # Final output layer\n",
    "        output = output.squeeze(0) # B x N\n",
    "        output = F.log_softmax(self.out(torch.cat((output, context), 1)))\n",
    "        \n",
    "        # Return final output, hidden state, and attention weights (for visualization)\n",
    "        return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Luong et al. model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LuongAttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, attn_model, hidden_size, output_size, n_layers=1, dropout=0.1):\n",
    "        super(LuongAttnDecoderRNN, self).__init__()\n",
    "\n",
    "        # Keep for reference\n",
    "        self.attn_model = attn_model\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Define layers\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size, padding_idx=PAD_TOKEN)\n",
    "        self.embedding_dropout = nn.Dropout(dropout)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=dropout)\n",
    "        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        # Choose attention model\n",
    "        if attn_model != 'none':\n",
    "            self.attn = Attn(attn_model, hidden_size)\n",
    "\n",
    "    def forward(self, input_seq, last_hidden, encoder_outputs):\n",
    "        # Note: we run this one step at a time\n",
    "\n",
    "        # Get the embedding of the current input word (last output word)\n",
    "        batch_size = input_seq.size(0)\n",
    "        embedded = self.embedding(input_seq)\n",
    "        embedded = self.embedding_dropout(embedded)\n",
    "        embedded = embedded.view(1, batch_size, self.hidden_size) # S=1 x B x N\n",
    "\n",
    "        # Get current hidden state from input word and last hidden state\n",
    "        rnn_output, hidden = self.gru(embedded, last_hidden)\n",
    "\n",
    "        # Calculate attention from current RNN state and all encoder outputs;\n",
    "        # apply to encoder outputs to get weighted average\n",
    "        attn_weights = self.attn(rnn_output, encoder_outputs)\n",
    "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1)) # B x S=1 x N\n",
    "\n",
    "        # Attentional vector using the RNN hidden state and context vector\n",
    "        # concatenated together (Luong eq. 5)\n",
    "        rnn_output = rnn_output.squeeze(0) # S=1 x B x N -> B x N\n",
    "        context = context.squeeze(1)       # B x S=1 x N -> B x N\n",
    "        concat_input = torch.cat((rnn_output, context), 1)\n",
    "        concat_output = F.tanh(self.concat(concat_input))\n",
    "\n",
    "        # Finally predict next token (Luong eq. 6, without softmax)\n",
    "        output = self.out(concat_output)\n",
    "\n",
    "        # Return final output, hidden state, and attention weights (for visualization)\n",
    "        return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(src_batch, src_lens, trg_batch, trg_lens, encoder, decoder, \n",
    "               encoder_optimizer, decoder_optimizer, criterion):\n",
    "    \n",
    "    # Zero gradients of both optimizers\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    #loss = 0 # Added onto for each word\n",
    "\n",
    "    # Run words through encoder\n",
    "    encoder_outputs, encoder_hidden = encoder(src_batch, src_lens, None)\n",
    "    \n",
    "    # Prepare input and output variables\n",
    "    decoder_input = Variable(torch.LongTensor([START_TOKEN] * batch_size))\n",
    "    decoder_hidden = encoder_hidden[:decoder.n_layers] # Use last (forward) hidden state from encoder\n",
    "\n",
    "    max_trg_len = max(trg_lens)\n",
    "    all_decoder_outputs = Variable(torch.zeros(max_trg_len, batch_size, decoder.output_size))\n",
    "\n",
    "    # Move new Variables to CUDA\n",
    "    if USE_CUDA:\n",
    "        decoder_input = decoder_input.cuda()\n",
    "        all_decoder_outputs = all_decoder_outputs.cuda()\n",
    "\n",
    "    # Run through decoder one time step at a time\n",
    "    for t in range(max_trg_len):\n",
    "        decoder_output, decoder_hidden, decoder_attn = decoder(\n",
    "            decoder_input, decoder_hidden, encoder_outputs\n",
    "        )\n",
    "\n",
    "        all_decoder_outputs[t] = decoder_output\n",
    "        decoder_input = trg_batch[t] # Next input is current target\n",
    "\n",
    "    # Loss calculation and backpropagation\n",
    "    loss = masked_cross_entropy(\n",
    "        all_decoder_outputs.transpose(0, 1).contiguous(), # -> batch x seq\n",
    "        trg_batch.transpose(0, 1).contiguous(), # -> batch x seq\n",
    "        trg_lens\n",
    "    )\n",
    "    loss.backward()\n",
    "    \n",
    "    # Clip gradient norms\n",
    "    enc_grads = torch.nn.utils.clip_grad_norm(encoder.parameters(), clip)\n",
    "    dec_grads = torch.nn.utils.clip_grad_norm(decoder.parameters(), clip)\n",
    "\n",
    "    # Update parameters with optimizers\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return loss.data[0]#, enc_grads, dec_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(encoder, decoder, checkpoint_dir):\n",
    "    enc_filename = \"{}/enc-{}.pth\".format(checkpoint_dir, time.strftime(\"%d%m%y-%H%M%S\"))\n",
    "    dec_filename = \"{}/dec-{}.pth\".format(checkpoint_dir, time.strftime(\"%d%m%y-%H%M%S\"))\n",
    "    #if not os.path.isfile(enc_filename):\n",
    "    #    open(enc_filename, 'w+')\n",
    "    #if not os.path.isfile(dec_filename):\n",
    "    #    open(dec_filename, 'w+')\n",
    "    torch.save(encoder.state_dict(), enc_filename)\n",
    "    torch.save(decoder.state_dict(), dec_filename)\n",
    "    print(\"Model saved.\")\n",
    "\n",
    "def train(dataset, batch_size, n_epochs, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, \n",
    "          checkpoint_dir=None, save_every=500):\n",
    "    train_iter = DataLoader(dataset=dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=True,\n",
    "                            num_workers=4,\n",
    "                            collate_fn=med_collate_fn)\n",
    "    for i in range(n_epochs):\n",
    "        print(\"Epoch {}/{}\".format(i+1, n_epochs))\n",
    "        losses = []\n",
    "        for batch_idx, batch in enumerate(train_iter):\n",
    "            tick = time.clock()\n",
    "            input_batch, input_lengths, target_batch, target_lengths = batch\n",
    "            loss = train_step(input_batch, input_lengths, target_batch, target_lengths, \n",
    "                                 encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "            losses.append(loss)\n",
    "            if batch_idx % 100 == 0:\n",
    "                print(\"batch: {}, loss: {}\".format(batch_idx, loss))\n",
    "            if checkpoint_dir:\n",
    "                if batch_idx % save_every == 0:\n",
    "                    save_checkpoint(encoder, decoder, checkpoint_dir)\n",
    "        tock = time.clock()\n",
    "        print(\"Time: {} Avg loss: {}\".format(tock-tick, np.mean(losses)))\n",
    "    \n",
    "    if checkpoint_dir:\n",
    "        save_checkpoint(encoder, decoder, checkpoint_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring and Initializing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure models\n",
    "attn_model = 'dot'\n",
    "hidden_size = 100\n",
    "embed_size = 300\n",
    "n_layers = 1\n",
    "dropout = 0.1\n",
    "batch_size = 20\n",
    "checkpoint_dir = \"checkpoints\"\n",
    "\n",
    "# Configure training/optimization\n",
    "clip = 50.0\n",
    "teacher_forcing_ratio = 0.5\n",
    "learning_rate = 0.0001\n",
    "decoder_learning_ratio = 5.0\n",
    "n_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dataset\n",
    "dataset = MEDDataset(\"data/german-task2-trainval\")\n",
    "\n",
    "# Initialize models\n",
    "encoder = EncoderRNN(len(dataset.in_vocab[0]), embed_size, hidden_size, n_layers, dropout=dropout)\n",
    "decoder = LuongAttnDecoderRNN(attn_model, hidden_size, len(dataset.out_vocab[0]), n_layers, dropout=dropout)\n",
    "\n",
    "# Initialize optimizers and criterion\n",
    "#encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "#decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n",
    "encoder_optimizer = optim.Adadelta(encoder.parameters())\n",
    "decoder_optimizer = optim.Adadelta(decoder.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Move models to GPU\n",
    "if USE_CUDA:\n",
    "    encoder.cuda()\n",
    "    decoder.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tome/anaconda3/envs/pytorch/lib/python3.6/site-packages/ipykernel/__main__.py:32: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/home/tome/faks/reinflection_projekt/Morphological-Encoder-Decoder/masked_cross_entropy.py:45: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_probs_flat = functional.log_softmax(logits_flat)\n",
      "/home/tome/faks/reinflection_projekt/Morphological-Encoder-Decoder/masked_cross_entropy.py:11: UserWarning: torch.range is deprecated in favor of torch.arange and will be removed in 0.3. Note that arange generates values in [start; end), not [start; end].\n",
      "  seq_range = torch.range(0, max_len - 1).long()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0, loss: 0.0938166007399559\n",
      "Model saved.\n",
      "batch: 100, loss: 0.07775372266769409\n",
      "batch: 200, loss: 0.08818323910236359\n",
      "batch: 300, loss: 0.09042157977819443\n",
      "batch: 400, loss: 0.09956632554531097\n",
      "batch: 500, loss: 0.11532220989465714\n",
      "Model saved.\n",
      "batch: 600, loss: 0.13629797101020813\n",
      "batch: 700, loss: 0.04213915020227432\n",
      "batch: 800, loss: 0.1004120260477066\n",
      "batch: 900, loss: 0.07554731518030167\n",
      "batch: 1000, loss: 0.10251795500516891\n",
      "Model saved.\n",
      "batch: 1100, loss: 0.08297096192836761\n",
      "batch: 1200, loss: 0.06600893288850784\n",
      "batch: 1300, loss: 0.10634999722242355\n",
      "batch: 1400, loss: 0.1032399907708168\n",
      "Time: 7.608835999999428 Avg loss: 0.08804052090789709\n",
      "Epoch 2/20\n",
      "batch: 0, loss: 0.09119533747434616\n",
      "Model saved.\n",
      "batch: 100, loss: 0.09812484681606293\n",
      "batch: 200, loss: 0.10361199080944061\n",
      "batch: 300, loss: 0.10692201554775238\n",
      "batch: 400, loss: 0.055498041212558746\n",
      "batch: 500, loss: 0.06949694454669952\n",
      "Model saved.\n",
      "batch: 600, loss: 0.07646659761667252\n",
      "batch: 700, loss: 0.09203486144542694\n",
      "batch: 800, loss: 0.10498853027820587\n",
      "batch: 900, loss: 0.08070074766874313\n",
      "batch: 1000, loss: 0.05957489460706711\n",
      "Model saved.\n",
      "batch: 1100, loss: 0.0655977800488472\n",
      "batch: 1200, loss: 0.0992908701300621\n",
      "batch: 1300, loss: 0.06944304704666138\n",
      "batch: 1400, loss: 0.06092897802591324\n",
      "Time: 2.791108000001259 Avg loss: 0.08466350812620173\n",
      "Epoch 3/20\n",
      "batch: 0, loss: 0.09934218227863312\n",
      "Model saved.\n",
      "batch: 100, loss: 0.0854484811425209\n",
      "batch: 200, loss: 0.08582312613725662\n",
      "batch: 300, loss: 0.11531461030244827\n",
      "batch: 400, loss: 0.160725399851799\n",
      "batch: 500, loss: 0.05340402573347092\n",
      "Model saved.\n",
      "batch: 600, loss: 0.07336130738258362\n",
      "batch: 700, loss: 0.09378183633089066\n",
      "batch: 800, loss: 0.05662549287080765\n",
      "batch: 900, loss: 0.09370788186788559\n",
      "batch: 1000, loss: 0.06134650111198425\n",
      "Model saved.\n",
      "batch: 1100, loss: 0.06247987598180771\n",
      "batch: 1200, loss: 0.10076474398374557\n",
      "batch: 1300, loss: 0.10449229925870895\n",
      "batch: 1400, loss: 0.06081221252679825\n",
      "Time: 2.860457000000679 Avg loss: 0.0805927212557031\n",
      "Epoch 4/20\n",
      "batch: 0, loss: 0.10088907927274704\n",
      "Model saved.\n",
      "batch: 100, loss: 0.11234161257743835\n",
      "batch: 200, loss: 0.06005643308162689\n",
      "batch: 300, loss: 0.11793921887874603\n",
      "batch: 400, loss: 0.07613071799278259\n",
      "batch: 500, loss: 0.07186508178710938\n",
      "Model saved.\n",
      "batch: 600, loss: 0.059053801000118256\n",
      "batch: 700, loss: 0.09979409724473953\n",
      "batch: 800, loss: 0.06971132755279541\n",
      "batch: 900, loss: 0.09490137547254562\n",
      "batch: 1000, loss: 0.060402870178222656\n",
      "Model saved.\n",
      "batch: 1100, loss: 0.09990665316581726\n",
      "batch: 1200, loss: 0.11259797215461731\n",
      "batch: 1300, loss: 0.11449746042490005\n",
      "batch: 1400, loss: 0.09047491103410721\n",
      "Time: 2.988148000000365 Avg loss: 0.07935416744763238\n",
      "Epoch 5/20\n",
      "batch: 0, loss: 0.1080671027302742\n",
      "Model saved.\n",
      "batch: 100, loss: 0.07099919766187668\n",
      "batch: 200, loss: 0.07872958481311798\n",
      "batch: 300, loss: 0.07080387324094772\n",
      "batch: 400, loss: 0.08228430151939392\n",
      "batch: 500, loss: 0.04875228554010391\n",
      "Model saved.\n",
      "batch: 600, loss: 0.08458269387483597\n",
      "batch: 700, loss: 0.07435578852891922\n",
      "batch: 800, loss: 0.0641060546040535\n",
      "batch: 900, loss: 0.11504802107810974\n",
      "batch: 1000, loss: 0.07780764251947403\n",
      "Model saved.\n",
      "batch: 1100, loss: 0.09095568209886551\n",
      "batch: 1200, loss: 0.06472200155258179\n",
      "batch: 1300, loss: 0.07967688143253326\n",
      "batch: 1400, loss: 0.08804231882095337\n",
      "Time: 3.31112000000212 Avg loss: 0.07606369094509217\n",
      "Epoch 6/20\n",
      "batch: 0, loss: 0.058880116790533066\n",
      "Model saved.\n",
      "batch: 100, loss: 0.06754522770643234\n",
      "batch: 200, loss: 0.06553494930267334\n",
      "batch: 300, loss: 0.07809045910835266\n",
      "batch: 400, loss: 0.04781678691506386\n",
      "batch: 500, loss: 0.05327385291457176\n",
      "Model saved.\n",
      "batch: 600, loss: 0.09028283506631851\n",
      "batch: 700, loss: 0.10984621942043304\n",
      "batch: 800, loss: 0.07701173424720764\n",
      "batch: 900, loss: 0.07251745462417603\n",
      "batch: 1000, loss: 0.11776784807443619\n",
      "Model saved.\n",
      "batch: 1100, loss: 0.0767943486571312\n",
      "batch: 1200, loss: 0.06642325222492218\n",
      "batch: 1300, loss: 0.07055963575839996\n",
      "batch: 1400, loss: 0.0815681517124176\n",
      "Time: 3.5132809999995516 Avg loss: 0.0740114805715469\n",
      "Epoch 7/20\n",
      "batch: 0, loss: 0.07852507382631302\n",
      "Model saved.\n",
      "batch: 100, loss: 0.06947207450866699\n",
      "batch: 200, loss: 0.05010773241519928\n",
      "batch: 300, loss: 0.06377064436674118\n",
      "batch: 400, loss: 0.07517728954553604\n",
      "batch: 500, loss: 0.05444169417023659\n",
      "Model saved.\n",
      "batch: 600, loss: 0.10073745250701904\n",
      "batch: 700, loss: 0.07249616831541061\n",
      "batch: 800, loss: 0.10791753232479095\n",
      "batch: 900, loss: 0.04722093045711517\n",
      "batch: 1000, loss: 0.06927922368049622\n",
      "Model saved.\n",
      "batch: 1100, loss: 0.07620245218276978\n",
      "batch: 1200, loss: 0.0825543999671936\n",
      "batch: 1300, loss: 0.10582436621189117\n",
      "batch: 1400, loss: 0.06963112950325012\n",
      "Time: 3.509600000001228 Avg loss: 0.07291556246475213\n",
      "Epoch 8/20\n",
      "batch: 0, loss: 0.10082293301820755\n",
      "Model saved.\n",
      "batch: 100, loss: 0.09043528884649277\n",
      "batch: 200, loss: 0.05865888297557831\n",
      "batch: 300, loss: 0.05693458020687103\n",
      "batch: 400, loss: 0.06255859136581421\n",
      "batch: 500, loss: 0.08564779162406921\n",
      "Model saved.\n",
      "batch: 600, loss: 0.06361012905836105\n",
      "batch: 700, loss: 0.07341849058866501\n",
      "batch: 800, loss: 0.04762006551027298\n",
      "batch: 900, loss: 0.06148114427924156\n",
      "batch: 1000, loss: 0.06915994733572006\n",
      "Model saved.\n",
      "batch: 1100, loss: 0.07256347686052322\n",
      "batch: 1200, loss: 0.052056021988391876\n",
      "batch: 1300, loss: 0.03589300811290741\n",
      "batch: 1400, loss: 0.06410155445337296\n",
      "Time: 3.1466550000041025 Avg loss: 0.07028643789882254\n",
      "Epoch 9/20\n",
      "batch: 0, loss: 0.054392777383327484\n",
      "Model saved.\n",
      "batch: 100, loss: 0.06010624021291733\n",
      "batch: 200, loss: 0.05019872635602951\n",
      "batch: 300, loss: 0.04854355379939079\n",
      "batch: 400, loss: 0.05918509513139725\n",
      "batch: 500, loss: 0.06044033169746399\n",
      "Model saved.\n",
      "batch: 600, loss: 0.04879056289792061\n",
      "batch: 700, loss: 0.04221509397029877\n",
      "batch: 800, loss: 0.04854016751050949\n",
      "batch: 900, loss: 0.07934854924678802\n",
      "batch: 1000, loss: 0.0676739513874054\n",
      "Model saved.\n",
      "batch: 1100, loss: 0.058998409658670425\n",
      "batch: 1200, loss: 0.04149992763996124\n",
      "batch: 1300, loss: 0.05574602633714676\n",
      "batch: 1400, loss: 0.061714738607406616\n",
      "Time: 2.73568399999931 Avg loss: 0.06905897451926851\n",
      "Epoch 10/20\n",
      "batch: 0, loss: 0.052138712257146835\n",
      "Model saved.\n",
      "batch: 100, loss: 0.054728686809539795\n",
      "batch: 200, loss: 0.05979650467634201\n",
      "batch: 300, loss: 0.07307910174131393\n",
      "batch: 400, loss: 0.06386110931634903\n",
      "batch: 500, loss: 0.05045310780405998\n",
      "Model saved.\n",
      "batch: 600, loss: 0.08794734627008438\n",
      "batch: 700, loss: 0.045837752521038055\n",
      "batch: 800, loss: 0.0644630417227745\n",
      "batch: 900, loss: 0.08080688118934631\n",
      "batch: 1000, loss: 0.1165812537074089\n",
      "Model saved.\n",
      "batch: 1100, loss: 0.045372460037469864\n",
      "batch: 1200, loss: 0.05366884917020798\n",
      "batch: 1300, loss: 0.04382602125406265\n",
      "batch: 1400, loss: 0.10478860884904861\n",
      "Time: 3.0750219999972614 Avg loss: 0.06666698096604604\n",
      "Epoch 11/20\n",
      "batch: 0, loss: 0.07295645773410797\n",
      "Model saved.\n",
      "batch: 100, loss: 0.04715365171432495\n",
      "batch: 200, loss: 0.052097003906965256\n",
      "batch: 300, loss: 0.0591290108859539\n",
      "batch: 400, loss: 0.0495491661131382\n",
      "batch: 500, loss: 0.058864567428827286\n",
      "Model saved.\n",
      "batch: 600, loss: 0.05384877696633339\n",
      "batch: 700, loss: 0.053164780139923096\n",
      "batch: 800, loss: 0.07182534039020538\n",
      "batch: 900, loss: 0.08286438882350922\n",
      "batch: 1000, loss: 0.07653220742940903\n",
      "Model saved.\n",
      "batch: 1100, loss: 0.08117717504501343\n",
      "batch: 1200, loss: 0.06309989839792252\n",
      "batch: 1300, loss: 0.03742828220129013\n",
      "batch: 1400, loss: 0.04168258607387543\n",
      "Time: 2.6471719999972265 Avg loss: 0.06483963010185916\n",
      "Epoch 12/20\n",
      "batch: 0, loss: 0.07894615828990936\n",
      "Model saved.\n",
      "batch: 100, loss: 0.03970978781580925\n",
      "batch: 200, loss: 0.06026352569460869\n",
      "batch: 300, loss: 0.0748608186841011\n",
      "batch: 400, loss: 0.032810769975185394\n",
      "batch: 500, loss: 0.0603574700653553\n",
      "Model saved.\n",
      "batch: 600, loss: 0.04431357607245445\n",
      "batch: 700, loss: 0.06432092189788818\n",
      "batch: 800, loss: 0.0645003616809845\n",
      "batch: 900, loss: 0.07473208755254745\n",
      "batch: 1000, loss: 0.06418655067682266\n",
      "Model saved.\n",
      "batch: 1100, loss: 0.07833411544561386\n",
      "batch: 1200, loss: 0.04871688410639763\n",
      "batch: 1300, loss: 0.05873808264732361\n",
      "batch: 1400, loss: 0.0551394484937191\n",
      "Time: 3.613913000001048 Avg loss: 0.06355016199587327\n",
      "Epoch 13/20\n",
      "batch: 0, loss: 0.04306367412209511\n",
      "Model saved.\n",
      "batch: 100, loss: 0.040812063962221146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 200, loss: 0.09301576763391495\n",
      "batch: 300, loss: 0.06577248126268387\n",
      "batch: 400, loss: 0.04670990630984306\n",
      "batch: 500, loss: 0.04785948619246483\n",
      "Model saved.\n",
      "batch: 600, loss: 0.05382851883769035\n",
      "batch: 700, loss: 0.06299955397844315\n",
      "batch: 800, loss: 0.04456329718232155\n",
      "batch: 900, loss: 0.051211338490247726\n",
      "batch: 1000, loss: 0.03968752548098564\n",
      "Model saved.\n",
      "batch: 1100, loss: 0.06290365010499954\n",
      "batch: 1200, loss: 0.07142247259616852\n",
      "batch: 1300, loss: 0.05029969662427902\n",
      "batch: 1400, loss: 0.04861556366086006\n",
      "Time: 4.265283999993699 Avg loss: 0.06273533622863599\n",
      "Epoch 14/20\n",
      "batch: 0, loss: 0.06890632212162018\n",
      "Model saved.\n",
      "batch: 100, loss: 0.0837448239326477\n",
      "batch: 200, loss: 0.026669073849916458\n",
      "batch: 300, loss: 0.11368023604154587\n",
      "batch: 400, loss: 0.057306185364723206\n",
      "batch: 500, loss: 0.07321836054325104\n",
      "Model saved.\n",
      "batch: 600, loss: 0.07043231278657913\n",
      "batch: 700, loss: 0.06098862364888191\n",
      "batch: 800, loss: 0.08574335277080536\n",
      "batch: 900, loss: 0.07100269943475723\n",
      "batch: 1000, loss: 0.04736649617552757\n",
      "Model saved.\n",
      "batch: 1100, loss: 0.03907089680433273\n",
      "batch: 1200, loss: 0.0572177916765213\n",
      "batch: 1300, loss: 0.05312987044453621\n",
      "batch: 1400, loss: 0.03580359369516373\n",
      "Time: 3.2033880000017234 Avg loss: 0.06070390819804743\n",
      "Epoch 15/20\n",
      "batch: 0, loss: 0.03264070302248001\n",
      "Model saved.\n",
      "batch: 100, loss: 0.08935539424419403\n",
      "batch: 200, loss: 0.039463140070438385\n",
      "batch: 300, loss: 0.026532603427767754\n",
      "batch: 400, loss: 0.05308562517166138\n",
      "batch: 500, loss: 0.04813425615429878\n",
      "Model saved.\n",
      "batch: 600, loss: 0.08716628700494766\n",
      "batch: 700, loss: 0.044147226959466934\n",
      "batch: 800, loss: 0.0538199320435524\n",
      "batch: 900, loss: 0.04196353256702423\n",
      "batch: 1000, loss: 0.06240494176745415\n",
      "Model saved.\n",
      "batch: 1100, loss: 0.06063467636704445\n",
      "batch: 1200, loss: 0.0913889929652214\n",
      "batch: 1300, loss: 0.08258326351642609\n",
      "batch: 1400, loss: 0.08136259764432907\n",
      "Time: 2.722386000008555 Avg loss: 0.05944071117426372\n",
      "Epoch 16/20\n",
      "batch: 0, loss: 0.05417106673121452\n",
      "Model saved.\n",
      "batch: 100, loss: 0.06125852093100548\n",
      "batch: 200, loss: 0.052727002650499344\n",
      "batch: 300, loss: 0.0791940987110138\n",
      "batch: 400, loss: 0.03690597414970398\n",
      "batch: 500, loss: 0.07675066590309143\n",
      "Model saved.\n",
      "batch: 600, loss: 0.08384750783443451\n",
      "batch: 700, loss: 0.05544617399573326\n",
      "batch: 800, loss: 0.1173262670636177\n",
      "batch: 900, loss: 0.06601491570472717\n",
      "batch: 1000, loss: 0.0649058148264885\n",
      "Model saved.\n",
      "batch: 1100, loss: 0.0415763184428215\n",
      "batch: 1200, loss: 0.1007685661315918\n",
      "batch: 1300, loss: 0.05187423154711723\n",
      "batch: 1400, loss: 0.1257655918598175\n",
      "Time: 3.8332939999963855 Avg loss: 0.05848946661895348\n",
      "Epoch 17/20\n",
      "batch: 0, loss: 0.029242118820548058\n",
      "Model saved.\n",
      "batch: 100, loss: 0.05291392281651497\n",
      "batch: 200, loss: 0.06787313520908356\n",
      "batch: 300, loss: 0.06006255000829697\n",
      "batch: 400, loss: 0.11937585473060608\n",
      "batch: 500, loss: 0.09445589780807495\n",
      "Model saved.\n",
      "batch: 600, loss: 0.03581884875893593\n",
      "batch: 700, loss: 0.06745776534080505\n",
      "batch: 800, loss: 0.044900111854076385\n",
      "batch: 900, loss: 0.0692523866891861\n",
      "batch: 1000, loss: 0.03645705059170723\n",
      "Model saved.\n",
      "batch: 1100, loss: 0.055095043033361435\n",
      "batch: 1200, loss: 0.056197695434093475\n",
      "batch: 1300, loss: 0.022884797304868698\n",
      "batch: 1400, loss: 0.06944834440946579\n",
      "Time: 4.020546999992803 Avg loss: 0.056712584210456246\n",
      "Epoch 18/20\n",
      "batch: 0, loss: 0.035293031483888626\n",
      "Model saved.\n",
      "batch: 100, loss: 0.07104124873876572\n",
      "batch: 200, loss: 0.026439305394887924\n",
      "batch: 300, loss: 0.05367881432175636\n",
      "batch: 400, loss: 0.04797401651740074\n",
      "batch: 500, loss: 0.08411364257335663\n",
      "Model saved.\n",
      "batch: 600, loss: 0.06956224143505096\n",
      "batch: 700, loss: 0.07438968867063522\n",
      "batch: 800, loss: 0.057313788682222366\n",
      "batch: 900, loss: 0.0707300677895546\n",
      "batch: 1000, loss: 0.05236434191465378\n",
      "Model saved.\n",
      "batch: 1100, loss: 0.0704202726483345\n",
      "batch: 1200, loss: 0.046615492552518845\n",
      "batch: 1300, loss: 0.03732630982995033\n",
      "batch: 1400, loss: 0.052695613354444504\n",
      "Time: 3.5880960000067716 Avg loss: 0.055096173164848654\n",
      "Epoch 19/20\n",
      "batch: 0, loss: 0.04428786784410477\n",
      "Model saved.\n",
      "batch: 100, loss: 0.051531556993722916\n",
      "batch: 200, loss: 0.05804237723350525\n",
      "batch: 300, loss: 0.06060975044965744\n",
      "batch: 400, loss: 0.06668487936258316\n",
      "batch: 500, loss: 0.046252552419900894\n",
      "Model saved.\n",
      "batch: 600, loss: 0.06947797536849976\n",
      "batch: 700, loss: 0.06670882552862167\n",
      "batch: 800, loss: 0.0971122533082962\n",
      "batch: 900, loss: 0.07328955829143524\n",
      "batch: 1000, loss: 0.0531221367418766\n",
      "Model saved.\n",
      "batch: 1100, loss: 0.07284058630466461\n",
      "batch: 1200, loss: 0.04630015417933464\n",
      "batch: 1300, loss: 0.03434652090072632\n",
      "batch: 1400, loss: 0.03267747163772583\n",
      "Time: 2.7091749999963213 Avg loss: 0.054964523727539925\n",
      "Epoch 20/20\n",
      "batch: 0, loss: 0.0655883178114891\n",
      "Model saved.\n",
      "batch: 100, loss: 0.058013007044792175\n",
      "batch: 200, loss: 0.036793000996112823\n",
      "batch: 300, loss: 0.026860661804676056\n",
      "batch: 400, loss: 0.050870709121227264\n",
      "batch: 500, loss: 0.059401024132966995\n",
      "Model saved.\n",
      "batch: 600, loss: 0.09844529628753662\n",
      "batch: 700, loss: 0.05516418442130089\n",
      "batch: 800, loss: 0.08396022766828537\n",
      "batch: 900, loss: 0.0402631051838398\n",
      "batch: 1000, loss: 0.04046621173620224\n",
      "Model saved.\n",
      "batch: 1100, loss: 0.07592916488647461\n",
      "batch: 1200, loss: 0.07041607052087784\n",
      "batch: 1300, loss: 0.05520908161997795\n",
      "batch: 1400, loss: 0.07877469807863235\n",
      "Time: 3.4406569999991916 Avg loss: 0.05296742118791574\n",
      "Model saved.\n"
     ]
    }
   ],
   "source": [
    "#encoder.load_state_dict(torch.load(\"checkpoints/enc-160518-101204.pth\"))\n",
    "#decoder.load_state_dict(torch.load(\"checkpoints/dec-160518-101204.pth\"))\n",
    "\n",
    "train(dataset, \n",
    "      batch_size, \n",
    "      n_epochs, \n",
    "      encoder, \n",
    "      decoder, \n",
    "      encoder_optimizer, \n",
    "      decoder_optimizer, \n",
    "      criterion, \n",
    "      checkpoint_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(input_seq, input_len, encoder, decoder, max_length=40):\n",
    "    #input_lengths = [len(input_seq)]\n",
    "    #input_seqs = [indexes_from_sentence(input_lang, input_seq)]\n",
    "    #input_batches = Variable(torch.LongTensor(input_seqs), volatile=True).transpose(0, 1)\n",
    "    input_seq = Variable(input_seq, volatile=True)\n",
    "    \n",
    "    if USE_CUDA:\n",
    "        input_seq = input_seq.cuda()\n",
    "        \n",
    "    # Set to not-training mode to disable dropout\n",
    "    encoder.train(False)\n",
    "    decoder.train(False)\n",
    "    \n",
    "    # Run through encoder\n",
    "    encoder_outputs, encoder_hidden = encoder(input_seq, input_len, None)\n",
    "\n",
    "    # Create starting vectors for decoder\n",
    "    decoder_input = Variable(torch.LongTensor([START_TOKEN]), volatile=True) # SOS\n",
    "    decoder_hidden = encoder_hidden[:decoder.n_layers] # Use last (forward) hidden state from encoder\n",
    "    \n",
    "    if USE_CUDA:\n",
    "        decoder_input = decoder_input.cuda()\n",
    "\n",
    "    # Store output words and attention states\n",
    "    decoded_chars = []\n",
    "    decoder_attentions = torch.zeros(max_length + 1, max_length + 1)\n",
    "    \n",
    "    # Run through decoder\n",
    "    for t in range(max_length):\n",
    "        decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "            decoder_input, decoder_hidden, encoder_outputs\n",
    "        )\n",
    "        #decoder_attentions[t,:decoder_attention.size(2)] += decoder_attention.squeeze(0).squeeze(0).cpu().data\n",
    "\n",
    "        # Choose top word from output\n",
    "        prob, token_idx = decoder_output.data.topk(1)\n",
    "        tok = token_idx[0][0]\n",
    "        if tok == END_TOKEN:\n",
    "            break\n",
    "        else:\n",
    "            decoded_chars.append(dataset.out_vocab[0][tok])\n",
    "            \n",
    "        # Next input is chosen word\n",
    "        decoder_input = Variable(torch.LongTensor([tok]))\n",
    "        if USE_CUDA: decoder_input = decoder_input.cuda()\n",
    "\n",
    "    # Set back to training mode\n",
    "    encoder.train(True)\n",
    "    decoder.train(True)\n",
    "    \n",
    "    return \"\".join(decoded_chars), decoder_attentions[:t+1, :len(encoder_outputs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_dataset(file_name, encoder, decoder):\n",
    "    dataset = MEDDataset(file_name, train=False)\n",
    "    test_iter = DataLoader(dataset=dataset,\n",
    "                           batch_size=1,\n",
    "                            shuffle=False,\n",
    "                            num_workers=4,\n",
    "                            collate_fn=med_collate_fn)\n",
    "    \n",
    "    decoded_words = []\n",
    "    for input_seq, input_len, _, _ in test_iter:\n",
    "        decoded_word, attentions = translate(input_seq, input_len, encoder, decoder)\n",
    "        decoded_words.append(decoded_word)\n",
    "        \n",
    "    with open(file_name + \"-results2\", 'w') as outfile:\n",
    "        outfile.write(\"\\n\".join(decoded_words))\n",
    "    print(\"Finished translating!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tome/anaconda3/envs/pytorch/lib/python3.6/site-packages/ipykernel/__main__.py:32: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished translating!\n"
     ]
    }
   ],
   "source": [
    "translate_dataset(\"data/german-task2-test\", encoder, decoder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
